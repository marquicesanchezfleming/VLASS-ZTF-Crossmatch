{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import glob\n",
    "from astropy.io import fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from astropy.time import Time\n",
    "import ssl\n",
    "from ztfquery.utils import stamps\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import csv\n",
    "import logging\n",
    "import urllib.request\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "fname = \"VLASS_dyn_summary.php\"\n",
    "url = 'https://archive-new.nrao.edu/vlass/VLASS_dyn_summary.php'\n",
    "output_file = 'CSV'\n",
    "\n",
    "urllib.request.urlretrieve(url, output_file)\n",
    "print(f'File downloaded to: {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tiles Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles():\n",
    "    \"\"\" Get tiles\n",
    "    I ran wget https://archive-new.nrao.edu/vlass/VLASS_dyn_summary.php\n",
    "    \"\"\"\n",
    "\n",
    "    inputf = open(fname, \"r\")\n",
    "    lines = inputf.readlines()\n",
    "    inputf.close()\n",
    "\n",
    "    header = list(filter(None, lines[0].split(\"  \")))\n",
    "\n",
    "    header = np.array([val.strip() for val in header])\n",
    "\n",
    "    names = []\n",
    "    dec_min = []\n",
    "    dec_max = []\n",
    "    ra_min = []\n",
    "    ra_max = []\n",
    "    obsdate = []\n",
    "    epoch = []\n",
    "\n",
    "    for line in lines[3:]:\n",
    "        dat = list(filter(None, line.split(\"  \")))\n",
    "        dat = np.array([val.strip() for val in dat])\n",
    "        names.append(dat[0])\n",
    "        dec_min.append(float(dat[1]))\n",
    "        dec_max.append(float(dat[2]))\n",
    "        ra_min.append(float(dat[3]))\n",
    "        ra_max.append(float(dat[4]))\n",
    "        obsdate.append(dat[6])\n",
    "        epoch.append(dat[5])\n",
    "\n",
    "    names = np.array(names)\n",
    "    dec_min = np.array(dec_min)\n",
    "    dec_max = np.array(dec_max)\n",
    "    ra_min = np.array(ra_min)\n",
    "    ra_max = np.array(ra_max)\n",
    "    obsdate = np.array(obsdate)\n",
    "    epoch = np.array(epoch)\n",
    "\n",
    "    return names, dec_min, dec_max, ra_min, ra_max, epoch, obsdate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Tiles Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tiles(tiles, c):\n",
    "    \"\"\" Now that you've processed the file, search for the given RA and Dec\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    c: SkyCoord object\n",
    "    \"\"\"\n",
    "    ra_h = c.ra.hour\n",
    "    dec_d = c.dec.deg\n",
    "    names, dec_min, dec_max, ra_min, ra_max, epochs, obsdate = tiles\n",
    "    has_dec = np.logical_and(dec_d > dec_min, dec_d < dec_max)\n",
    "    has_ra = np.logical_and(ra_h > ra_min, ra_h < ra_max)\n",
    "    in_tile = np.logical_and(has_ra, has_dec)\n",
    "    name = names[in_tile]\n",
    "    epoch = epochs[in_tile]\n",
    "    date = obsdate[in_tile]\n",
    "    if len(name) == 0:\n",
    "        print(\"Sorry, no tile found.\")\n",
    "        return None, None, None\n",
    "    else:\n",
    "        return name, epoch, date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Subtiles Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtiles(tilename, epoch):\n",
    "    \"\"\" For a given tile name, get the filenames in the VLASS directory.\n",
    "    Parse those filenames and return a list of subtile RA and Dec.\n",
    "    RA and Dec returned as a SkyCoord object\n",
    "    \"\"\"\n",
    "    if epoch == 'VLASS1.2':\n",
    "        epoch = 'VLASS1.2v2'\n",
    "    elif epoch == 'VLASS1.1':\n",
    "        epoch = 'VLASS1.1v2'\n",
    "    url_full = 'https://archive-new.nrao.edu/vlass/quicklook/%s/%s/' % (epoch, tilename)\n",
    "    print(url_full)\n",
    "    urlpath = urlopen(url_full)\n",
    "\n",
    "    string = (urlpath.read().decode('utf-8')).split(\"\\n\")\n",
    "\n",
    "    vals = np.array([val.strip() for val in string])\n",
    "\n",
    "    keep_link = np.array([\"href\" in val.strip() for val in string])\n",
    "\n",
    "    keep_name = np.array([tilename in val.strip() for val in string])\n",
    "\n",
    "    string_keep = vals[np.logical_and(keep_link, keep_name)]\n",
    "\n",
    "    fname = np.array([val.split(\"\\\"\")[7] for val in string_keep])\n",
    "\n",
    "    pos_raw = np.array([val.split(\".\")[4] for val in fname])\n",
    "\n",
    "    ra = []\n",
    "    dec = []\n",
    "\n",
    "    for ii in range(len(pos_raw)):\n",
    "        rah = pos_raw[ii][1:3]\n",
    "        if rah == \"24\":\n",
    "            rah = \"00\"\n",
    "        ram = pos_raw[ii][3:5]\n",
    "        ras = pos_raw[ii][5:7]\n",
    "        decd = pos_raw[ii][7:10]\n",
    "        decm = pos_raw[ii][10:12]\n",
    "        decs = pos_raw[ii][12:]\n",
    "        hms = \"%sh%sm%ss\" % (rah, ram, ras)\n",
    "        ra.append(hms)\n",
    "        dms = \"%sd%sm%ss\" % (decd, decm, decs)\n",
    "        dec.append(dms)\n",
    "    ra = np.array(ra)\n",
    "    dec = np.array(dec)\n",
    "    c_tiles = SkyCoord(ra, dec, frame='icrs')\n",
    "    return fname, c_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Cutout Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"/Users/Djslime07/Documents/GitHub/VLASS-ZTF-Crossmatch/Images\"\n",
    "def get_cutout(imname, name, c, epoch):\n",
    "    print(\"Generating cutout\")\n",
    "    # Position of source\n",
    "    ra_deg = c.ra.deg\n",
    "    dec_deg = c.dec.deg\n",
    "\n",
    "    print(\"Cutout centered at position %s, %s\" % (ra_deg, dec_deg))\n",
    "\n",
    "    # Open image and establish coordinate system\n",
    "    try:\n",
    "        with pyfits.open(imname, ignore_missing_simple=True) as hdulist:\n",
    "            im = hdulist[0].data[0, 0]\n",
    "            if im.size == 0:\n",
    "                print(\"Error: Image data is empty.\")\n",
    "                return None\n",
    "\n",
    "            w = WCS(hdulist[0].header)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading image data: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Find the source position in pixels\n",
    "    src_pix = w.wcs_world2pix([[ra_deg, dec_deg, 0, 0]], 0)\n",
    "    x = src_pix[0, 0]\n",
    "    y = src_pix[0, 1]\n",
    "\n",
    "    # Check if the source is actually in the image\n",
    "    pix1 = hdulist[0].header['CRPIX1']\n",
    "    pix2 = hdulist[0].header['CRPIX2']\n",
    "    badx = np.logical_or(x < 0, x > 2 * pix1)\n",
    "    bady = np.logical_or(y < 0, y > 2 * pix2)\n",
    "    if np.logical_and(badx, bady):\n",
    "        print(\"Tile has not been imaged at the position of the source\")\n",
    "        return None\n",
    "    else:\n",
    "        # Set the dimensions of the image\n",
    "        image_dim_arcsec = 12\n",
    "        delt1 = hdulist[0].header['CDELT1']\n",
    "        delt2 = hdulist[0].header['CDELT2']\n",
    "        cutout_size = image_dim_arcsec / 3600  # in degrees\n",
    "        dside1 = -cutout_size / 2. / delt1\n",
    "        dside2 = cutout_size / 2. / delt2\n",
    "\n",
    "        vmin = -1e-4\n",
    "        vmax = 1e-3\n",
    "\n",
    "        im_plot_raw = im[int(y - dside1):int(y + dside1), int(x - dside2):int(x + dside2)]\n",
    "        im_plot = np.ma.masked_invalid(im_plot_raw)\n",
    "\n",
    "        # 3-sigma clipping\n",
    "        rms_temp = np.ma.std(im_plot)\n",
    "        keep = np.ma.abs(im_plot) <= 3 * rms_temp\n",
    "        rms = np.ma.std(im_plot[keep])\n",
    "\n",
    "        if im_plot.flatten().size == 0:\n",
    "            print(\"Tile has not been imaged at the position of the source\")\n",
    "            return None\n",
    "        else:\n",
    "            peak_flux = np.ma.max(im_plot.flatten())\n",
    "\n",
    "\n",
    "        save_path = os.path.join(save_directory, f\"{name}_{epoch}.png\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "        ax.imshow(np.flipud(im_plot),\n",
    "            extent=[-0.5 * cutout_size * 3600., 0.5 * cutout_size * 3600.,\n",
    "                    -0.5 * cutout_size * 3600., 0.5 * cutout_size * 3600],\n",
    "            vmin=vmin, vmax=vmax, cmap='YlOrRd')\n",
    "\n",
    "        peakstr = \"Peak Flux %s mJy\" % (np.round(peak_flux * 1e3, 3))\n",
    "        rmsstr = \"RMS Flux %s mJy\" % (np.round(rms * 1e3, 3))\n",
    "\n",
    "        plt.title(name + \": %s; \\n %s\" % (peakstr, rmsstr))\n",
    "        plt.xlabel(\"Offset in RA (arcsec)\")\n",
    "        plt.ylabel(\"Offset in Dec (arcsec)\")\n",
    "\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(\"PNG Downloaded Successfully\")\n",
    "\n",
    "        return peak_flux, rms\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "csv_file_path = \"/Users/Djslime07/Documents/GitHub/VLASS-ZTF-Crossmatch/bts_data.CSV\"\n",
    "ddir = \"/Users/Djslime07/Documents/GitHub/VLASS-ZTF-Crossmatch/Images\"\n",
    "download_folder = '/Users/Djslime07/Documents/GitHub/VLASS-ZTF-Crossmatch/Images'\n",
    "\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search(name, c, date=None):\n",
    "    \"\"\"\n",
    "    Searches the VLASS catalog for a source\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: name of the sources\n",
    "    c: coordinates as SkyCoord object\n",
    "    date: date in astropy Time format\n",
    "    \"\"\"\n",
    "    print(\"Running for %s\" % name)\n",
    "    print(\"Coordinates %s\" % c)\n",
    "    print(\"Date: %s\" % date)\n",
    "\n",
    "    # Define the download folder\n",
    "    download_folder = \"./Images\"  # Update to your desired path\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "    # Find the VLASS tile(s)\n",
    "    tiles = get_tiles()\n",
    "    tilenames, epochs, obsdates = search_tiles(tiles, c)\n",
    "\n",
    "    past_epochs = [\"VLASS1.1v2\", \"VLASS1.2v2\", \"VLASS2.1\", \"VLASS2.2\", \"VLASS3.1\"]\n",
    "    current_epoch = \"VLASS3.2\"\n",
    "\n",
    "    if tilenames[0] is None:\n",
    "        print(\"There is no VLASS tile at this location\")\n",
    "\n",
    "    else:\n",
    "        for ii, tilename in enumerate(tilenames):\n",
    "            print()\n",
    "            print(\"Looking for tile observation for %s\" % tilename)\n",
    "            epoch = epochs[ii]\n",
    "            obsdate = obsdates[ii]\n",
    "\n",
    "            if obsdate == \"Not submitted\":\n",
    "                print(f\"No valid observation date for tile {tilename} in epoch {epoch}\")\n",
    "                continue  # Skip this tile\n",
    "\n",
    "            # Adjust name so it works with the version 2 ones for 1.1 and 1.2\n",
    "            if epoch == 'VLASS1.2':\n",
    "                epoch = 'VLASS1.2v2'\n",
    "            elif epoch == 'VLASS1.1':\n",
    "                epoch = 'VLASS1.1v2'\n",
    "\n",
    "            if epoch not in past_epochs:\n",
    "                if epoch == current_epoch:\n",
    "                    # Make list of observed tiles\n",
    "                    url_full = 'https://archive-new.nrao.edu/vlass/quicklook/%s/' % (epoch)\n",
    "                    urlpath = urlopen(url_full)\n",
    "                    # Get site HTML coding\n",
    "                    string = (urlpath.read().decode('utf-8')).split(\"\\n\")\n",
    "                    # Clean the HTML elements of trailing and leading whitespace\n",
    "                    vals = np.array([val.strip() for val in string])\n",
    "                    # Make list of useful html elements\n",
    "                    files = np.array(['alt=\"[DIR]\"' in val.strip() for val in string])\n",
    "                    useful = vals[files]\n",
    "                    # Splice out the name from the link\n",
    "                    obsname = np.array([val.split(\"\\\"\")[7] for val in useful])\n",
    "                    observed_current_epoch = np.char.replace(obsname, '/', '')\n",
    "\n",
    "                    # Check if tile has been observed yet for the current epoch\n",
    "                    if epoch not in observed_current_epoch:\n",
    "                        print(\"Sorry, tile will be observed later in this epoch\")\n",
    "                else:\n",
    "                    print(\"Sorry, tile will be observed in a later epoch\")\n",
    "            else:\n",
    "                print(\"Tile Found:\")\n",
    "                print(tilename, epoch)\n",
    "                subtiles, c_tiles = get_subtiles(tilename, epoch)\n",
    "                # Find angular separation from the tiles to the location\n",
    "                dist = c.separation(c_tiles)\n",
    "                # Find tile with the smallest separation\n",
    "                subtile = subtiles[np.argmin(dist)]\n",
    "                url_get = \"https://archive-new.nrao.edu/vlass/quicklook/%s/%s/%s\" % (\n",
    "                    epoch, tilename, subtile)\n",
    "                imname = \"%s.I.iter1.image.pbcor.tt0.subim.fits\" % subtile[0:-1]\n",
    "\n",
    "                # Update the FITS filename with ZTF name and epoch number\n",
    "                local_imname = os.path.join(download_folder, f\"{name}_{imname}\")\n",
    "\n",
    "                # Print URL for downloading\n",
    "                fname = os.path.join(url_get, imname)\n",
    "                print(fname)\n",
    "\n",
    "                # Check if the file already exists in the specified folder\n",
    "                if not os.path.exists(local_imname):\n",
    "                    # Download the file\n",
    "                    cmd = f\"curl -o '{local_imname}' '{fname}'\"\n",
    "                    print(cmd)\n",
    "                    os.system(cmd)\n",
    "                else:\n",
    "                    print(f\"{local_imname} already exists. Skipping download.\")\n",
    "\n",
    "                # Get image cutout and save FITS data as png\n",
    "                out = get_cutout(local_imname, name, c, epoch)\n",
    "                if out is not None:\n",
    "                    peak, rms = out\n",
    "                    output_file = \"/Users/Djslime07/Documents/GitHub/VLASS-ZTF-Crossmatch/CSV's/Fluxes_and_RMS.csv\"\n",
    "                    with open(output_file, 'a') as f:\n",
    "                        print(\n",
    "                            f\"{name}_{epoch}.png has a peak flux of {np.round(peak * 1e3, 3)} and a RMS of {np.round(rms * 1e3, 3)}\",\n",
    "                            file=f)\n",
    "                    print(rms, peak)\n",
    "\n",
    "                    print(\"Peak flux is %s uJy\" % (peak * 1e6))\n",
    "                    print(\"RMS is %s uJy\" % (rms * 1e6))\n",
    "                    limit = rms * 1e6\n",
    "                    obsdate = Time(obsdate, format='iso').mjd\n",
    "\n",
    "                    output_file = \"/Users/Djslime07/Documents/GitHub/VLASS-ZTF-Crossmatch/CSV's/VLASS_Observations.csv\"\n",
    "                    with open(output_file, 'a') as f:\n",
    "                        print(f\"{name}_{epoch}.png observed on {obsdate}\", file=f)\n",
    "                    print(limit, obsdate)\n",
    "                    os.remove(imname)\n",
    "\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Survey Cutout Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ls_cutout(ddir, name, ra_str, dec_str, outputf):\n",
    "    \"\"\" Plot cutout from Legacy Survey \"\"\"\n",
    "    # Create a SkyCoord object from ra_str and dec_str\n",
    "    coord = SkyCoord(ra_str, dec_str, unit=(\"hour\", \"degree\"))\n",
    "\n",
    "    fname = os.path.join(ddir, f\"{name}_LegSurvey.png\")\n",
    "\n",
    "    if not os.path.isfile(fname):\n",
    "        url = f\"http://legacysurvey.org/viewer/cutout.jpg?ra={coord.ra.deg}&dec={coord.dec.deg}&layer=ls-dr9&pixscale=0.27&bands=grz\"\n",
    "        plt.figure(figsize=(2.1, 2.1), dpi=120)\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            img = Image.open(io.BytesIO(r.content))\n",
    "            plt.imshow(img)\n",
    "            plt.title(\"LegSurv DR9\", fontsize=12)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(fname, bbox_inches=\"tight\")\n",
    "\n",
    "            decsign = '+' if coord.dec.deg >= 0 else '-'\n",
    "            lslinkstr = f\"http://legacysurvey.org/viewer?ra={coord.ra.deg:.6f}&dec={decsign}{abs(coord.dec.deg):.6f}&zoom=16&layer=dr9\"\n",
    "            outputf.write(f\"<a href='{lslinkstr}'>\")\n",
    "            outputf.write(f'<img src=\"{name}_LegSurvey.png\" height=\"200\">')\n",
    "            outputf.write(\"</a>\")\n",
    "            outputf.write('<br>')\n",
    "        except Exception as e:\n",
    "            # Not in footprint or another error\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            plt.close()\n",
    "\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pan-STARRS Cutout Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ps1_cutout(ddir, name, ra_str, dec_str, outputf):\n",
    "    \"\"\" Plot cutout from PanSTARRS \"\"\"\n",
    "    # Create a SkyCoord object from ra_str and dec_str\n",
    "    coord = SkyCoord(ra_str, dec_str, unit=(\"hour\", \"degree\"))\n",
    "\n",
    "    fname = os.path.join(ddir, f\"{name}_ps1.png\")\n",
    "\n",
    "    if not os.path.isfile(fname):\n",
    "        img = stamps.get_ps_stamp(coord.ra.deg, coord.dec.deg, size=240, color=[\"y\", \"g\", \"i\"])\n",
    "        plt.figure(figsize=(2.1, 2.1), dpi=120)\n",
    "        plt.imshow(np.asarray(img))\n",
    "        plt.title(\"PS1 (y/g/i)\", fontsize=12)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fname, bbox_inches=\"tight\")\n",
    "\n",
    "        decsign = '+' if coord.dec.deg >= 0 else '-'\n",
    "        pslinkstr = f\"https://ps1images.stsci.edu/cgi-bin/ps1cutouts?ra={coord.ra.deg:.6f}&dec={decsign}{abs(coord.dec.deg):.6f}&size=240&format=jpeg&filters=ygi\"\n",
    "        outputf.write(f\"<a href='{pslinkstr}'>\")\n",
    "        outputf.write(f'<img src=\"{name}_ps1.png\" height=\"200\">')\n",
    "        outputf.write(\"</a>\")\n",
    "        outputf.write('<br>')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Object Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_object(row):\n",
    "    \"\"\"Process a single object given a row from the CSV.\"\"\"\n",
    "    name = row['name']\n",
    "    ra = row['ra']\n",
    "    dec = row['dec']\n",
    "    Obj = SkyCoord(ra, dec, unit=(\"hourangle\", \"deg\"))\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Processing object {name} at RA: {ra}, Dec: {dec}\")\n",
    "        run_search(name, Obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to process object {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process CSV Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(csv_file_path, start_line=0, end_line=None):\n",
    "    with open(csv_file_path, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for idx, row in enumerate(reader):\n",
    "            if idx < start_line:\n",
    "                continue\n",
    "            if end_line is not None and idx > end_line:\n",
    "                break\n",
    "            process_object(row)\n",
    "\n",
    "start_line = 1989  # If you want line x, then do (x-2) for the actual line\n",
    "end_line = 1989  # The last line to process -2\n",
    "\n",
    "process_csv(csv_file_path, start_line, end_line)\n",
    "\n",
    "logging.info(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description= \\\n",
    "                                         '''\n",
    "                                         Searches VLASS for a source.\n",
    "                                         User needs to supply name, RA (in decimal degrees),\n",
    "                                         Dec (in decimal degrees), and (optionally) date (in mjd).\n",
    "                                         If there is a date, then will only return VLASS images taken after that date\n",
    "                                         (useful for transients with known explosion dates).\n",
    "                                 \n",
    "                                         Usage: vlass_search.py <Name> <RA [deg]> <Dec [deg]> <(optional) Date [mjd]>\n",
    "                                         ''', formatter_class=argparse.RawTextHelpFormatter)\n",
    "\n",
    "    if len(sys.argv) < 3:\n",
    "        print(\"Usage: vlass_search.py <Name> <RA [deg]> <Dec [deg]> <(optional) Date [astropy Time]>\")\n",
    "        sys.exit()\n",
    "\n",
    "    name = str(sys.argv[1])\n",
    "    ra = float(sys.argv[2])\n",
    "    dec = float(sys.argv[3])\n",
    "    c = SkyCoord(ra, dec, unit='deg')\n",
    "\n",
    "    if glob.glob(\"/Users/annaho/Dropbox/astro/tools/Query_VLASS/VLASS_dyn_summary.php\"):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Tile summary file is not here. Download it using wget:\\\n",
    "               wget https://archive-new.nrao.edu/vlass/VLASS_dyn_summary.php\")\n",
    "\n",
    "    if (len(sys.argv) > 4):\n",
    "        date = Time(float(sys.argv[4]), format='mjd')\n",
    "        print('Searching for observations after %s' % date)\n",
    "        run_search(name, c, date)\n",
    "    else:\n",
    "        print('Searching all obs dates')\n",
    "        run_search(name, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
